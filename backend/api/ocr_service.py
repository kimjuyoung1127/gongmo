"""
Clova OCR ì„œë¹„ìŠ¤ ëª¨ë“ˆ
ì˜ìˆ˜ì¦ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ ê´€ë ¨ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§
"""
import os
import requests
import time
import base64
import re
import json
import hashlib
import google.generativeai as genai
from PIL import Image
from io import BytesIO
from supabase import create_client

# utils í´ë”ì˜ í•¨ìˆ˜ë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ê°€ì ¸ì˜´
from .utils.expiry_logic import _get_category_id_by_name, _get_category_expiry_days
from .cache_manager import ocr_memory_cache

# supabase í´ë¼ì´ì–¸íŠ¸ ìƒì„±
supabase_url = os.environ.get('SUPABASE_URL')
supabase_key = os.environ.get('SUPABASE_ANON_KEY')
supabase = create_client(supabase_url, supabase_key) if supabase_url and supabase_key else None

# --- í™˜ê²½ ë³€ìˆ˜ ë° API ì„¤ì • ---
CLOVA_OCR_API_URL = os.environ.get('CLOVA_OCR_API_URL')
CLOVA_OCR_SECRET_KEY = os.environ.get('CLOVA_OCR_SECRET_KEY')
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

# Gemini API ì„¤ì •
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
else:
    print("[WARN] GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")


def call_clova_ocr(image_data):
    """
    í´ë¡œë°” OCR APIë¥¼ í˜¸ì¶œí•˜ì—¬ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    try:
        print(f"[CLOVA] í´ë¡œë°” OCR API í˜¸ì¶œ ì‹œì‘")
        headers = {"X-OCR-SECRET": CLOVA_OCR_SECRET_KEY, "Content-Type": "application/json"}
        image_base64 = base64.b64encode(image_data).decode('utf-8')
        data = {
            "images": [{"format": "jpg", "name": "receipt", "data": image_base64}],
            "requestId": "scan_" + str(int(time.time())),
            "version": "V2",
            "timestamp": int(time.time() * 1000)
        }
        
        response = requests.post(CLOVA_OCR_API_URL, headers=headers, json=data, timeout=60)
        
        if response.status_code == 200:
            print(f"[CLOVA] í´ë¡œë°” OCR API í˜¸ì¶œ ì„±ê³µ")
            return response.json()
        else:
            print(f"[CLOVA] í´ë¡œë°” OCR API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
            
    except Exception as e:
        print(f"[CLOVA] í´ë¡œë°” OCR í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        return None


def _reconstruct_lines_from_boxes(fields):
    """
    OCR í•„ë“œë“¤ì„ ì¢Œí‘œ ê¸°ë°˜ìœ¼ë¡œ ì¤„(Line) ë‹¨ìœ„ë¡œ ì¬ì¡°ë¦½í•˜ì—¬ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    """
    if not fields:
        return ""
        
    # Yì¢Œí‘œë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„ë“œ ì •ë ¬ (ìœ„ì—ì„œ ì•„ë˜ë¡œ)
    fields.sort(key=lambda f: f['boundingPoly']['vertices'][0]['y'])
    
    lines = []
    current_line = []
    last_y = fields[0]['boundingPoly']['vertices'][0]['y']

    for field in fields:
        text = field['inferText']
        y_coord = field['boundingPoly']['vertices'][0]['y']

        # Yì¢Œí‘œê°€ í¬ê²Œ ë³€í•˜ë©´ ì¤„ë°”ê¿ˆìœ¼ë¡œ ê°„ì£¼ (ì¤„ ë†’ì´ì˜ 50% ì´ìƒ ì°¨ì´)
        if y_coord - last_y > 15: # ì„ê³„ê°’ (ì¡°ì • ê°€ëŠ¥)
            lines.append(" ".join([item['text'] for item in sorted(current_line, key=lambda item: item['x'])]))
            current_line = []
        
        current_line.append({'text': text, 'x': field['boundingPoly']['vertices'][0]['x']})
        last_y = y_coord

    if current_line:
        # xì¢Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìµœì¢… ë¼ì¸ ì¶”ê°€
        sorted_line = [item['text'] for item in sorted(current_line, key=lambda item: item['x'])]
        lines.append(" ".join(sorted_line))

    full_text = "\n".join(lines)
    print(f"[LAYOUT] ì¬êµ¬ì„±ëœ ì „ì²´ í…ìŠ¤íŠ¸:\n---\n{full_text}\n---")
    return full_text


async def _extract_items_with_llm(full_text):
    """
    LLM(Gemini)ì„ ì‚¬ìš©í•˜ì—¬ ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    if not GEMINI_API_KEY:
        print("[LLM-ERROR] Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ ìƒí’ˆ ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return []

    try:
        print("[LLM] Gemini API í˜¸ì¶œ ì‹œì‘...")
        model = genai.GenerativeModel('gemini-2.5-flash')

        # ì¹´í…Œê³ ë¦¬ ëª©ë¡ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        categories_info = """
        1: ìœ ì œí’ˆ(ì‹ ì„ ) - ğŸ¥›
        2: ìœ ì œí’ˆ(ê°€ê³µ/ë¡±ë¼ì´í”„) - ğŸ§ˆ
        3: ì—°ì§ˆì¹˜ì¦ˆ - ğŸ§€
        4: ê²½ì„±ì¹˜ì¦ˆ - ğŸ§€
        5: ìœ¡ë¥˜(ì‹ ì„ ) - ğŸ¥©
        6: ê°€ê³µìœ¡ - ğŸ¥“
        7: ë‚œë¥˜ - ğŸ¥š
        8: ìì±„ì†Œ - ğŸ¥¬
        9: ì¤„ê¸°ì±„ì†Œ - ğŸ¥’
        10: ë¿Œë¦¬ì±„ì†Œ(ì €ì˜¨) - ğŸ 
        11: ë°œì•„ì±„ì†Œ - ğŸŒ±
        12: ì—´ë§¤ì±„ì†Œ - ğŸ…
        13: ë²„ì„¯ë¥˜ - ğŸ„
        14: ê³¼ì¼(ì¼ë°˜) - ğŸ
        15: ë² ë¦¬ë¥˜ - ğŸ“
        16: ê°ê·¤ë¥˜ - ğŸŠ
        17: ì—´ëŒ€ê³¼ì¼ - ğŸ¥­
        18: ì–´ë¥˜(ì‹ ì„ ) - ğŸŸ
        19: íŒ¨ë¥˜ - ğŸ¦
        20: ì—°ì²´/ê°‘ê°ë¥˜ - ğŸ¦€
        21: í•´ì¡°ë¥˜(ìƒ) - ğŸ¥¬
        22: í•´ì¡°ë¥˜(ê±´ì¡°) - ğŸ¥¬
        23: ëƒ‰ë™ì‹í’ˆ - â„ï¸
        24: ê±´ë©´ - ğŸ
        25: ìƒ/ëƒ‰ì¥ë©´ - ğŸœ
        26: ë¹µ(ì¼ë°˜) - ğŸ
        27: ë² ì´ì»¤ë¦¬(í¬ë¦¼/ìƒŒë“œ) - ğŸ¥®
        28: ìŒë£Œ(ëƒ‰ì¥) - ğŸ¥¤
        29: ìŒë£Œ(ë©¸ê· /ìº”) - ğŸ¥¤
        30: ê³¼ì/ìŠ¤ë‚µ - ğŸª
        31: ê³¡ë¥˜/ìŒ€ - ğŸŒ¾
        32: ì†ŒìŠ¤/ì¡°ë¯¸ë£Œ - ğŸ§‚
        33: ê¹€ì¹˜/ì ˆì„ë¥˜ - ğŸ¥—
        34: í†µì¡°ë¦¼/ê±´ì‹í’ˆ - ğŸ¥«
        35: ë°˜ì¡°ë¦¬/ëƒ‰ì¥ HMR - ğŸ½ï¸
        36: ë°˜ì¡°ë¦¬/ëƒ‰ë™ HMR - ğŸ½ï¸
        37: ê¸°íƒ€ - ğŸ“¦
        """

        prompt = f"""
        ë‹¹ì‹ ì€ ì˜ìˆ˜ì¦ì„ ë¶„ì„í•˜ì—¬ ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ë¥¼ ì •í™•í•˜ê²Œ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒì€ OCRë¡œ ìŠ¤ìº”ëœ ì˜ìˆ˜ì¦ í…ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

        --- ì˜ìˆ˜ì¦ í…ìŠ¤íŠ¸ ---
        {full_text}
        --- ì˜ìˆ˜ì¦ í…ìŠ¤íŠ¸ ë ---

        ìœ„ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ìŒ ê·œì¹™ì„ ì—„ê²©í•˜ê²Œ ì§€ì¼œ 'ìƒí’ˆëª…'ê³¼ 'ì¹´í…Œê³ ë¦¬ ID'ë¥¼ í•¨ê»˜ ì¶”ì¶œí•˜ê³ , ê·¸ ì™¸ ëª¨ë“  í…ìŠ¤íŠ¸ëŠ” ì™„ë²½í•˜ê²Œ ë¬´ì‹œí•˜ì‹­ì‹œì˜¤.

        **ì¹´í…Œê³ ë¦¬ ëª©ë¡:**
        {categories_info}

        **ê·œì¹™:**
        1. ìƒí’ˆëª…, ìˆ˜ëŸ‰, ë‹¨ê°€ì™€ ì§ì ‘ì ìœ¼ë¡œ ê´€ë ¨ëœ í…ìŠ¤íŠ¸ë§Œ ìƒí’ˆìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤.
        2. ê°€ê²Œ ì´ë¦„, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸, ì‚¬ì—…ìë²ˆí˜¸, ë‚ ì§œ, ì‹œê°„, í•©ê³„, ë¶€ê°€ì„¸, í• ì¸, ê²°ì œ ì •ë³´, ì¹´ë“œ ë²ˆí˜¸, ìŠ¹ì¸ ë²ˆí˜¸ ë“±ì€ ì ˆëŒ€ ìƒí’ˆì´ ì•„ë‹™ë‹ˆë‹¤.
        3. OCR ì˜¤ë¥˜ë¡œ ë³´ì´ëŠ” ì˜ë¯¸ ì—†ëŠ” ë¬¸ìì—´(ì˜ˆ: 'ê·¸ì•¡', 'ë“€í˜¸ì›”í˜¸ì‹œì•¡')ì€ ìƒí’ˆì´ ì•„ë‹™ë‹ˆë‹¤.
        4. ìˆ˜ëŸ‰ì´ë‚˜ ê°€ê²©ë§Œ ë‚˜íƒ€ë‚´ëŠ” ìˆ«ì(ì˜ˆ: '1', '4,500')ëŠ” ìƒí’ˆì´ ì•„ë‹™ë‹ˆë‹¤.
        5. ì¹´í…Œê³ ë¦¬ëŠ” ìœ„ì˜ ëª©ë¡ì—ì„œ ê°€ì¥ ì ì ˆí•œ ê²ƒì„ ì„ íƒí•˜ì‹­ì‹œì˜¤. ì •í™•í•œ ë§¤ì¹­ì´ ì—†ìœ¼ë©´ 37(ê¸°íƒ€)ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
        6. ìˆ˜ëŸ‰ ì •ë³´ê°€ ëª…ì‹œë˜ì–´ ìˆë‹¤ë©´ í•¨ê»˜ ì¶”ì¶œí•˜ë˜, ê¸°ë³¸ê°’ì€ 1ì…ë‹ˆë‹¤.
        7. ì¶”ì¶œëœ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•´ì•¼ í•©ë‹ˆë‹¤. ì„¤ëª…ì´ë‚˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´, ì˜¤ì§ JSONë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

        **ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ:**
        [
          {{"item_name": "ê³„ë€", "category_id": 8, "quantity": 1}},
          {{"item_name": "ì†Œê³ ê¸°", "category_id": 6, "quantity": 1}},
          {{"item_name": "ë”¸ê¸°", "category_id": 16, "quantity": 1}}
        ]
        """

        response = model.generate_content(prompt)

        # ì‘ë‹µì—ì„œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
        response_text = response.text
        print(f"[LLM-DEBUG] API ì›ë³¸ ì‘ë‹µ: {response_text}")

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(` ```json ... ``` `)ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
        match = re.search(r'```json\s*([\s\S]*?)\s*```', response_text)
        if match:
            json_text = match.group(1)
        else:
            json_text = response_text

        print(f"[LLM-DEBUG] íŒŒì‹±í•  JSON í…ìŠ¤íŠ¸: {json_text}")

        items_data = json.loads(json_text)

        if isinstance(items_data, list):
            print(f"[LLM-SUCCESS] ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ {len(items_data)}ê°œ ì¶”ì¶œ ì„±ê³µ: {[item['item_name'] for item in items_data]}")
            return items_data
        else:
            print(f"[LLM-ERROR] ì‘ë‹µì´ JSON ë°°ì—´ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤: {items_data}")
            return []

    except Exception as e:
        print(f"[LLM-ERROR] Gemini API í˜¸ì¶œ ë˜ëŠ” íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []


async def parse_clova_response_to_items(clova_response):
    """
    í´ë¡œë°” OCR ì‘ë‹µì„ LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆ í•­ëª©ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    try:
        if 'images' not in clova_response or not clova_response['images']:
            print("[PARSER] ì‘ë‹µì— ì´ë¯¸ì§€ ë°ì´í„° ì—†ìŒ")
            return []

        fields = clova_response['images'][0].get('fields', [])

        # 1. OCR í…ìŠ¤íŠ¸ ì¬êµ¬ì„±
        print(f"[PARSER] 1. ë ˆì´ì•„ì›ƒ ë¶„ì„ ë° ì „ì²´ í…ìŠ¤íŠ¸ ì¬êµ¬ì„± ì‹œì‘...")
        full_text = _reconstruct_lines_from_boxes(fields)

        # 2. ìºì‹œ í•´ì‹œ ìƒì„±
        ocr_hash = _generate_ocr_hash(full_text)

        # 3. ë©”ëª¨ë¦¬ ìºì‹œ ë¨¼ì € í™•ì¸ (0.1s)
        memory_result = ocr_memory_cache.get(ocr_hash)
        if memory_result:
            print(f"[MEMORY-HIT] ë©”ëª¨ë¦¬ ìºì‹œ ì ì¤‘ (0.1s): {ocr_hash[:8]}...")
            return memory_result

        # 4. ìºì‹œ í™•ì¸ (0.5s)
        cached_result = await _get_cached_parse_result(ocr_hash)
        if cached_result:
            # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
            ocr_memory_cache.set(ocr_hash, cached_result)
            return cached_result

        # 5. ìºì‹œ ë¯¸ìŠ¤ ì‹œ LLM í˜¸ì¶œ (3s)
        print(f"[LLM-CALL] ìºì‹œ ë¯¸ìŠ¤, Gemini API í˜¸ì¶œ: {ocr_hash[:8]}...")

        # 2. LLMì„ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¶”ì¶œ
        print(f"[PARSER] 2. LLM ê¸°ë°˜ ìƒí’ˆëª…ê³¼ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ ì‹œì‘...")
        items_with_category = await _extract_items_with_llm(full_text)

        if not items_with_category:
            print("[PARSER] LLMì´ ìƒí’ˆì„ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return []

        # 3. ì¶”ì¶œëœ ê° ìƒí’ˆëª…ì— ëŒ€í•´ ìœ í†µê¸°í•œ ì •ë³´ ì¶”ê°€ (ì¹´í…Œê³ ë¦¬ëŠ” ì´ë¯¸ LLMì—ì„œ ì œê³µë¨)
        print(f"[PARSER] 3. ìœ í†µê¸°í•œ ì •ë³´ ë§¤í•‘ ì‹œì‘...")
        final_items = []
        for item in items_with_category:
            item_name = item.get('item_name', '')
            category_id = item.get('category_id', 37)  # ê¸°ë³¸ê°’: ê¸°íƒ€(37)
            quantity = item.get('quantity', 1)

            # ì¹´í…Œê³ ë¦¬ IDë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹´í…Œê³ ë¦¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            from .utils.expiry_logic import get_category_info_by_id
            category_info = get_category_info_by_id(category_id)

            # ìœ íš¨í•˜ì§€ ì•Šì€ ì¹´í…Œê³ ë¦¬ IDì¸ ê²½ìš° ê¸°ë³¸ ì¹´í…Œê³ ë¦¬(ê¸°íƒ€)ë¡œ ëŒ€ì²´
            if not category_info:
                print(f"[WARN] Invalid category_id '{category_id}' received from LLM. Falling back to 'ê¸°íƒ€'.")
                category_id = 37  # 'ê¸°íƒ€' ì¹´í…Œê³ ë¦¬ì˜ ID
                category_info = get_category_info_by_id(category_id)

            category_name = category_info.get('category_name_kr', 'ê¸°íƒ€')
            expiry_days = category_info.get('default_expiry_days', 7)

            # ğŸ‘† category_idì™€ expiry_daysê¹Œì§€ ìºì‹œì— ì €ì¥í•˜ì—¬ ì†ë„ ìµœì í™”
            item_data = {
                'item_name': item_name,
                'category': category_name,
                'category_id': category_id,
                'expiry_days': expiry_days,
                'quantity': quantity,
                'unit': 'ê°œ',   # ê¸°ë³¸ê°’
                'source': 'clova_ocr_llm',
                'confidence_high': True, # LLM ê²°ê³¼ë¥¼ ì‹ ë¢°
                'raw_text': item_name
            }
            final_items.append(item_data)
            print(f"[PARSER-SUCCESS] âœ… ìƒí’ˆ ì²˜ë¦¬ ì™„ë£Œ: {item_name} (ID: {category_id}, {category_name})")

        # 6. ìºì‹œ ì €ì¥ (ì™„ì „ ì²˜ë¦¬ëœ ê²°ê³¼ë¬¼)
        _save_parse_cache(ocr_hash, final_items)
        ocr_memory_cache.set(ocr_hash, final_items)

        print(f"\n[PARSER-SUMMARY] ìµœì¢… ì¶”ì¶œëœ ìƒí’ˆ ìˆ˜: {len(final_items)}")
        return final_items

    except Exception as e:
        print(f"[PARSER] ìµœì¢… íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []


def _classify_product_category(item_name):
    """
    í™•ì¥ì„± ìˆëŠ” ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ê·œì¹™ ê¸°ë°˜ + í‚¤ì›Œë“œ ë§¤í•‘).
    """
    category_keywords = {
        'ì±„ì†Œ': ['ìƒì¶”', 'ê¹€ì¹˜', 'ë°°ì¶”', 'ì–‘ë°°ì¶”', 'ì‹œê¸ˆì¹˜', 'ê¹»ì', 'ì•„ìš±', 'íŒŒí”„ë¦¬ì¹´', 'ì˜¤ì´', 'ë²„ì„¯', 'ë¯¸ë‚˜ë¦¬', 'ë¬´', 'ë¯¸ì—­'],
        'ê³¼ì¼': ['ì‚¬ê³¼', 'ë°°', 'í¬ë„', 'ë³µìˆ­ì•„', 'ê°ê·¤', 'ìˆ˜ë°•', 'ì°¸ì™¸', 'ì˜¤ë Œì§€', 'ë ˆëª¬', 'ìë‘', 'ë”¸ê¸°', 'í‚¤ìœ„', 'ì²´ë¦¬', 'ë¸”ë£¨ë² ë¦¬'],
        'ìœ ì œí’ˆ': ['ìš°ìœ ', 'ì¹˜ì¦ˆ', 'ê³„ë€', 'ìš”ê±°íŠ¸', 'ë²„í„°', 'í¬ë¦¼', 'ë§ˆìš”ë„¤ì¦ˆ'],
        'ì •ìœ¡': ['ê³ ê¸°', 'ì†Œê³ ê¸°', 'ë¼ì§€ê³ ê¸°', 'ë‹­ê³ ê¸°', 'ì˜¤ë¦¬ê³ ê¸°', 'ì¹˜í‚¨', 'ì–‘', 'ê°ˆë¹„', 'ë¶ˆê³ ê¸°', 'ì¡±ë°œ', 'ì‚¼ê²¹ì‚´', 'ëˆê¹ŒìŠ¤'],
        'í•´ì‚°ë¬¼': ['ê³ ë“±ì–´', 'ì—°ì–´', 'ê°ˆì¹˜', 'ìƒˆìš°', 'ì¡°ê°œ', 'êµ´ë¹„', 'ë¬¸ì–´', 'ì˜¤ì§•ì–´', 'ë‚™ì§€', 'ì „ë³µ', 'ë©¸ì¹˜', 'ê°€ë¦¬ë¹„'],
        'ë¹µê³¼ê³¼ì': ['ë¹µ', 'ê³¼ì', 'ì¿ í‚¤', 'ì´ˆì½œë¦¿', 'ì¼€ì´í¬', 'íŒŒì´'],
        'ìŒë£Œ': ['ì£¼ìŠ¤', 'ìƒìˆ˜', 'ì»¤í”¼', 'ì°¨', 'ì†Œì£¼', 'ë§¥ì£¼', 'ì½œë¼', 'ì‚¬ì´ë‹¤', 'ì•„ë©”ë¦¬ì¹´ë…¸', 'ë¼ë–¼', 'ì—ìŠ¤í”„ë ˆì†Œ'],
        'ê°€ê³µì‹í’ˆ': ['ë¼ë©´', 'ë©´', 'íŒŒìŠ¤íƒ€', 'ì‹œë¦¬ì–¼', 'êµ­ìˆ˜', 'í†µì¡°ë¦¼', 'ì¦‰ì„ë°¥'],
        'ì¡°ë¯¸ë£Œ': ['ì„¤íƒ•', 'ì†Œê¸ˆ', 'ê°„ì¥', 'ê³ ì¶”ì¥', 'í›„ì¶”', 'ì‹ì´ˆ', 'ê¸°ë¦„'],
        'ëƒ‰ë™ì‹í’ˆ': ['ì•„ì´ìŠ¤í¬ë¦¼', 'ëƒ‰ë™ë§Œë‘', 'ëƒ‰ë™í”¼ì']
    }
    
    item_name_lower = item_name.lower()
    
    for category, keywords in category_keywords.items():
        for keyword in keywords:
            if keyword in item_name_lower:
                return category
    
    return 'ê¸°íƒ€'


def resize_image_for_clova(image_path, max_size=2000, quality=95):
    """
    í´ë¡œë°” OCR ì „ì†¡ì„ ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•©ë‹ˆë‹¤.
    """
    try:
        with Image.open(image_path) as img:
            if max(img.size) <= max_size:
                with open(image_path, 'rb') as f:
                    return f.read()

            ratio = max_size / max(img.size)
            new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
            img_resized = img.resize(new_size, Image.Resampling.LANCZOS)

            output_buffer = BytesIO()
            img_resized.convert('RGB').save(output_buffer, format='JPEG', quality=quality, optimize=True)
            return output_buffer.getvalue()

    except Exception as e:
        print(f"[CLOVA] ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨: {str(e)}")
        with open(image_path, 'rb') as f:
            return f.read()


def _normalize_ocr_text(ocr_text: str) -> str:
    """OCR í…ìŠ¤íŠ¸ ì •ê·œí™” - ì‹¤ì œ ì˜ìˆ˜ì¦ ë¡œê·¸ ê¸°ë°˜ ìµœì í™”"""
    normalized = ocr_text.strip()

    # 1. ì—°ì† ê³µë°± â†’ ë‹¨ì¼ ê³µë°±
    normalized = re.sub(r'\s+', ' ', normalized)

    # 2. ê´„í˜¸ ë° íŠ¹ìˆ˜ë¬¸ì ì œê±°
    normalized = re.sub(r'[()\-_\*\+\=\[\]{}<>|\\/]', ' ', normalized)

    # 3. ì˜ë¬¸ ì†Œë¬¸ì í†µì¼
    normalized = normalized.lower()

    # 4. ìµœì¢… ì •ë¦¬
    return ' '.join(normalized.split())


def _generate_ocr_hash(ocr_text: str) -> str:
    """ì •ê·œí™”ëœ OCR í…ìŠ¤íŠ¸ë¡œ SHA256 í•´ì‹œ ìƒì„±"""
    normalized_text = _normalize_ocr_text(ocr_text)
    return hashlib.sha256(normalized_text.encode('utf-8')).hexdigest()


async def _get_cached_parse_result(ocr_hash: str) -> dict:
    """Supabaseì—ì„œ ìºì‹œëœ íŒŒì‹± ê²°ê³¼ ì¡°íšŒ"""
    try:
        response = supabase.table('llm_parse_cache')\
            .select('final_items')\
            .eq('ocr_hash', ocr_hash)\
            .execute()

        if response.data and len(response.data) > 0:
            print(f"[CACHE-HIT] LLM ìºì‹œ ì ì¤‘ (0.5s): {ocr_hash[:8]}...")
            return response.data[0]['final_items']
    except Exception as e:
        print(f"[CACHE-ERROR] ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")

    return None


def _save_parse_cache(ocr_hash: str, final_items: list):
    """ìµœì¢… ì²˜ë¦¬ëœ ìƒí’ˆ ëª©ë¡ì„ ìºì‹œì— ì €ì¥"""
    try:
        cache_data = {
            'ocr_hash': ocr_hash,
            'final_items': final_items
        }

        supabase.table('llm_parse_cache').upsert(cache_data).execute()
        print(f"[CACHE-SAVE] LLM ê²°ê³¼ ìºì‹œ ì €ì¥: {ocr_hash[:8]}...")
    except Exception as e:
        print(f"[CACHE-ERROR] ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
