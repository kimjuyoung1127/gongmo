import google.generativeai as genai
import pandas as pd
import os
import time
from tqdm import tqdm
import re

# --- ì„¤ì • ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(os.path.dirname(BASE_DIR), 'data')

ORIGINAL_DATASET_PATH = os.path.join(DATA_DIR, 'food_dataset_v4_clean.csv')
SYNTHETIC_DATASET_PATH = os.path.join(DATA_DIR, 'food_dataset_v5_synthetic.csv')

# --- Gemini API ì„¤ì • ---
# í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ (ë³´ì•ˆì„ ìœ„í•´ ì§ì ‘ ì½”ë“œì— ë„£ì§€ ë§ˆì„¸ìš”)
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

if not GEMINI_API_KEY:
    print("âŒ ì˜¤ë¥˜: GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ìƒˆë¡œìš´ API í‚¤ë¥¼ ë°œê¸‰ë°›ì•„ í™˜ê²½ ë³€ìˆ˜ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
    exit()

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-2.5-flash')

# --- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ---
def create_synthetic_data_prompt(original_text, category, num_variations=10):
    """
    ê³ í’ˆì§ˆ ì˜ìˆ˜ì¦ ë…¸ì´ì¦ˆ ìƒì„± í”„ë¡¬í”„íŠ¸
    """
    prompt = f"""You are a Korean receipt OCR simulator. 
Your task is to generate realistic noisy variations of grocery product names as they appear on Korean receipts.

Original Product: {original_text}
Category: {category}
Number of Variations: {num_variations}

Generate {num_variations} realistic variations with the following noise patterns:

1. **Prefixes** (40% chance): (PB), *, [í• ], [íŠ¹ê°€], (í–‰ì‚¬), 7-SELECT)
2. **Suffixes** (60% chance): 1KG, 500g, 1L, 2L, /ê°œ, /ë´‰, í•œíŒ©
3. **OCR Errors** (20% chance): 0â†”O, 1â†”l, ìš°â†’ìš±, ìœ â†’ì¸„
4. **Space Removal** (30% chance): Remove random spaces

Examples:
- Input: "ì„œìš¸ìš°ìœ " â†’ Output: "*ì„œìš¸ìš°ìœ 1L", "[í• ]ì…”ìš±ìš°ìœ ", "ì„œìš¸ìš°ìœ 500ml/ê°œ"
- Input: "í–‡ê°ì" â†’ Output: "(PB)í–‡ê°ì1KG", "í–‡ê°ì/ë´‰", "[íŠ¹ê°€]í–‡ê°ì"

Generate ONLY the variations, no explanations.
"""
    return prompt

# --- í•©ì„± ë°ì´í„° ìƒì„± í•¨ìˆ˜ ---
def generate_synthetic_dataset(original_csv_path, output_csv_path, num_variations_per_sample=10):
    print("ğŸ”„ Gemini APIë¥¼ ì´ìš©í•œ í•©ì„± ë°ì´í„° ìƒì„± ì‹œì‘...")

    # 1. ì›ë³¸ ë°ì´í„° ë¡œë“œ
    try:
        df_original = pd.read_csv(original_csv_path)
        print(f"âœ… ì›ë³¸ ë°ì´í„°ì…‹ ë¡œë“œ: {len(df_original):,}ê°œ ìƒ˜í”Œ")
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ì›ë³¸ ë°ì´í„°ì…‹ '{original_csv_path}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    synthetic_data = []
    
    # 2. í•©ì„± ë°ì´í„° ìƒì„± ë£¨í”„
    # tqdmìœ¼ë¡œ ì§„í–‰ë¥  í‘œì‹œ
    for idx, row in tqdm(df_original.iterrows(), total=len(df_original), desc="í•©ì„± ë°ì´í„° ìƒì„± ì¤‘"):
        original_text = row['clean_text']
        category = row['category_code']
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = create_synthetic_data_prompt(original_text, category, num_variations_per_sample)
        
        try:
            # Gemini API í˜¸ì¶œ
            response = model.generate_content(prompt)
            
            # ì‘ë‹µ íŒŒì‹± ë° ì •ì œ
            variations = response.text.strip().split('\n')
            
            for variation in variations:
                cleaned_variation = variation.strip()
                # ë¹ˆ ë¬¸ìì—´ì´ê±°ë‚˜ ì›ë³¸ê³¼ ë™ì¼í•œ ê²½ìš° ì œì™¸ (ì„ íƒ ì‚¬í•­)
                if cleaned_variation and cleaned_variation != original_text:
                    synthetic_data.append({
                        'clean_text': cleaned_variation,
                        'category_code': category,
                        'source': 'gemini_synthetic',
                        'original_text': original_text # ì›ë³¸ í…ìŠ¤íŠ¸ ì¶”ì 
                    })
            
            # Rate limiting (ë¬´ë£Œ í‹°ì–´: 15 RPM = 1ë¶„ë‹¹ 15íšŒ ìš”ì²­, ì¦‰ 4ì´ˆì— 1íšŒ)
            time.sleep(4)
            
        except Exception as e:
            print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ (ì›ë³¸: '{original_text}'): {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ í•´ë‹¹ ìƒ˜í”Œì€ ê±´ë„ˆë›°ê³  ë‹¤ìŒìœ¼ë¡œ ì§„í–‰
            continue

    # 3. í•©ì„± ë°ì´í„°ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    df_synthetic = pd.DataFrame(synthetic_data)
    print(f"\nâœ… ì´ {len(df_synthetic):,}ê°œì˜ í•©ì„± ìƒ˜í”Œ ìƒì„± ì™„ë£Œ.")

    # 4. ì›ë³¸ ë°ì´í„°ì™€ í•©ì„± ë°ì´í„° ë³‘í•©
    # ì›ë³¸ ë°ì´í„°ì—ë„ 'source' ë° 'original_text' ì»¬ëŸ¼ ì¶”ê°€í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€
    df_original['source'] = 'original'
    df_original['original_text'] = df_original['clean_text']
    
    df_combined = pd.concat([df_original, df_synthetic], ignore_index=True)
    
    # ì¤‘ë³µ ì œê±° (clean_text ê¸°ì¤€ìœ¼ë¡œ)
    initial_len = len(df_combined)
    df_combined.drop_duplicates(subset=['clean_text', 'category_code'], inplace=True)
    print(f"âœ… ì¤‘ë³µ ì œê±° í›„ ìµœì¢… ìƒ˜í”Œ ìˆ˜: {len(df_combined):,}ê°œ (ì œê±°ëœ ì¤‘ë³µ: {initial_len - len(df_combined):,}ê°œ)")

    # 5. ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥
    try:
        df_combined.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… ìµœì¢… ë°ì´í„°ì…‹ '{os.path.basename(output_csv_path)}' ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None
    
    return df_combined

if __name__ == "__main__":
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ë¡œë“œí•˜ë„ë¡ ì„¤ì •
    # ì˜ˆ: export GEMINI_API_KEY='YOUR_API_KEY' (Linux/macOS)
    #     $env:GEMINI_API_KEY='YOUR_API_KEY' (PowerShell)
    #     set GEMINI_API_KEY=YOUR_API_KEY (CMD) 
    
    # í•©ì„± ë°ì´í„° ìƒì„± ì‹¤í–‰
    final_dataset = generate_synthetic_dataset(
        ORIGINAL_DATASET_PATH,
        SYNTHETIC_DATASET_PATH,
        num_variations_per_sample=10
    )
    
    if final_dataset is not None:
        print("\nğŸ‰ í•©ì„± ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print(f"   ìƒì„±ëœ íŒŒì¼: {SYNTHETIC_DATASET_PATH}")
        print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {len(final_dataset):,}ê°œ")
    else:
        print("\nâŒ í•©ì„± ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨.")
