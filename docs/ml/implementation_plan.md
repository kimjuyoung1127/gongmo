# OCR 품목 분류 모델 개선 최종 보고서

## 1. 최종 요약 (Executive Summary)

- **문제 정의**: 데이터 증강 및 다중 모델 실험에도 불구하고, 품목 분류 모델의 정확도가 **19%** 까지 하락하며 성능 개선에 실패.
- **원인 분석**: 모델 아키텍처가 아닌, **데이터의 피처(Feature) 품질**이 근본적인 문제임을 확인. 단순 텍스트 기반의 피처가 한국어 품목명의 복잡성을 반영하지 못함.
- **해결 방안**: 모델 중심 접근법을 폐기하고, **데이터 중심 접근법**으로 전략을 전면 수정.
  - **(핵심)** `Konlpy` 라이브러리의 `Okt` 형태소 분석기를 도입하여, 품목명에서 의미의 핵심이 되는 **명사만 추출**하는 고급 전처리 파이프라인 구축.
  - 노이즈를 유발했던 증강 데이터셋을 폐기하고, 정제된 순수 원본 데이터셋(`food_dataset_v4_clean.csv`)을 사용.
- **최종 결과**: 새로운 전처리 방식 적용 후, `LogisticRegression` 모델이 **테스트 정확도 61.59%**를 달성하며 기존 대비 **3배 이상**의 극적인 성능 향상을 이룸.
- **최종 결론**: 모델의 성능은 아키텍처보다 **데이터의 품질과 한국어에 특화된 피처 엔지니어링**에 결정적으로 좌우됨을 입증.

---

## 2. 최종 모델 상세

- **데이터셋**: `backend/data/food_dataset_v4_clean.csv` (1,385개 샘플)
- **전처리 파이프라인**: `train_model.py` (v4)
  1.  정규식을 통해 한글, 공백을 제외한 모든 노이즈(숫자, 특수문자, 영어) 제거.
  2.  `Okt` 형태소 분석기를 이용해 품목명에서 **명사만 추출**.
      - 예시: `(행사)서울우유 1L` → `서울 우유`
  3.  추출된 명사들을 `TfidfVectorizer`로 벡터화.
- **최종 모델**: `LogisticRegression`
  - `GridSearchCV`를 통해 탐색된 최적 하이퍼파라미터: `{'C': 50}`
- **최종 성능**:
  - **테스트 정확도: 61.59%**

---

## 3. 향후 개선 과제

- **고품질 데이터 추가 확보**: 현재 약 1,400개의 샘플은 37개 클래스를 분류하기에 절대적으로 부족. 성능을 85% 이상으로 끌어올리기 위한 최우선 과제.
- **임베딩 모델 도입**: `Word2Vec`, `FastText` 등 사전 훈련된 임베딩을 사용하여 단어의 의미적 관계를 학습시키면 성능 향상을 기대할 수 있음.
- **딥러닝 모델 실험**: 데이터가 충분히 확보된다는 전제 하에, LSTM, 1D-CNN 등 텍스트 분류에 특화된 딥러닝 모델을 적용하여 더 복잡한 패턴 학습.

---

<details>
<summary>📜 개발 과정 상세 (클릭하여 펼치기)</summary>

## MLOps v2 초기 계획

### 📋 개요

log.md에 기반한 OCR 품목 분류 모델의 라벨 체계를 Supabase DB 기준(36개 category_code)으로 전환하고, **"단일 진실 원천(Single Source of Truth)"**을 구축하는 단계별 구현 플랜입니다.

### 🎯 목표

1.  **데이터 정합성**: 모델-DB-API 동일한 category_code 사용
2.  **유지보수성**: category_map.pkl 의존성 제거, DB 실시간 조회
3.  **확장성**: 새 카테고리 추가 시 코드 수정 없이 자동 확장
4.  **MLOps**: 자동 재훈련 및 성능 추적 파이프라인

---

## 🚀 모델 성능 개선 플랜 (v2) - 실패 기록

**실행 결과 요약 (2025-11-14):**
- **목표**: 데이터 파이프라인 정비 및 모델 성능 개선
- **결과**:
  - **성공**: 계획에 따라 데이터 정합성 확보 및 스크립트 구조 개선 완료.
    - `categories_master.csv`를 단일 진실 원천으로 설정.
    - `food_dataset_v4_clean.csv` 및 `food_dataset_v4_augmented.csv` 생성 완료.
    - 모든 스크립트가 새 데이터셋과 파일 구조를 사용하도록 업데이트됨.
  - **실패**: 재훈련된 모델의 **정확도가 27.63%로 심각하게 하락함.**
- **결론**: 데이터 파이프라인은 개선되었으나, 모델 성능이 크게 저하되어 즉각적인 후속 조치가 필요함.

---

## 🚀 모델 성능 개선 플랜 (v3) - 성공 기록

**실행 결과 요약 (2025-11-14):**
- **문제 정의**: v2 계획(데이터 증강, 하이퍼파라미터 튜닝, 모델 아키텍처 변경) 실행 후, 모델 정확도가 **19.86%** 까지 하락. 모델이 아닌 **데이터의 피처(Feature) 문제**로 결론.
- **전략 수정**: 모델 중심 접근법을 폐기하고, **데이터 중심 접근법**으로 전면 전환.
- **해결책**:
  1.  **데이터셋 원복**: 노이즈를 유발하는 증강 데이터(`food_dataset_v5_augmented.csv`) 사용을 중단하고, 순수 원본 데이터셋(`food_dataset_v4_clean.csv`)으로 회귀.
  2.  **고급 전처리 도입**: `konlpy`의 `Okt` 형태소 분석기를 사용하여 품목명에서 **핵심 명사만 추출**하는 새로운 전처리 파이프라인을 `train_model.py`에 구현.
- **결과**:
  - **성공**: 새로운 전처리 파이프라인 적용 후, **정확도가 61.59%로 대폭 향상** (기존 19.86% 대비 **3배 이상** 성능 개선).
  - **최적 모델**: `LogisticRegression` (C=50)
- **결론**: 잘못된 데이터 증강과 피상적인 전처리가 성능 저하의 핵심 원인이었음. **한국어에 특화된 형태소 분석 기반의 피처 엔지니어링**이 성능 회복의 열쇠였음을 확인함.

### **Phase 5: 최종 모델 확정 및 결과**
- [x] **Action 5.1: 데이터 중심 전략으로 전환**
  - [x] `train_model.py` 수정: `food_dataset_v4_clean.csv`를 사용하도록 변경.
- [x] **Action 5.2: 한국어 형태소 분석기 기반 전처리 적용**
  - [x] `konlpy` 라이브러리 설치.
  - [x] `train_model.py`에 한글 및 공백 제외 모든 문자 제거, `Okt`를 사용한 명사 추출 로직 추가.
- [x] **Action 5.3: 최종 모델 재훈련 및 평가**
  - [x] 수정된 스크립트로 다중 모델(`LogisticRegression`, `SGDClassifier` 등) 재실험.
  - [x] `LogisticRegression`이 **61.59%** 의 테스트 정확도로 최고 성능을 기록.
  - [x] 최종 모델과 전처리기, 결과(`model_classes.json`)를 `models/` 디렉터리에 저장.

---

### **Phase 6: 프론트엔드 모듈화 및 유지보수 (2025-11-15)**

#### MLOps 프론트엔드 통합
- [x] **scan.tsx 모듈화**: 대규모 scan.tsx 파일을 기능별로 분리
  - [x] `ModeToggle.tsx`: 바코드/영수증 모드 전환 UI 분리
  - [x] `PhotoConfirmModal.tsx`: 사진 확인 모달 UI 분리
  - [x] `ScanUtils.ts`: 공통 유틸리티 함수 및 타입 정의 분리
- [x] **AI 모델 결과 통합**: 프론트엔드에서 ML 모델 분류 결과를 적절히 처리하도록 구현
- [x] **OCR 결과 처리**: PaddleOCR/클로바 OCR 결과를 모델 분류와 통합
- [x] **바코드 캐싱 시스템**: 사용자 입력 데이터가 모델 학습 데이터로 재사용되도록 DB 설계 완료

**최종 요약:**
모델 성능 저하 문제를 성공적으로 해결하고, 61.59% 정확도의 신규 모델을 확보하며 개선 작업을 마칩니다. 목표치인 85%에는 도달하지 못했으나, 향후 성능 개선을 위한 명확한 방향(고품질 데이터 추가, 임베딩 모델 도입 등)을 설정했습니다.

</details>
